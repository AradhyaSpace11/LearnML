{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Install neccesary libraries**"
      ],
      "metadata": {
        "id": "zSoV609k2NlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract\n",
        "!pip install sentence-transformers\n",
        "!pip install faiss-cpu\n",
        "!pip install pytesseract\n",
        "!apt-get install -y tesseract-ocr\n",
        "!pip install easyocr"
      ],
      "metadata": {
        "id": "kPkfeNr12SFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Lightweight Image to text code**"
      ],
      "metadata": {
        "id": "T0tRWNsfzzbv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bFd0iLlVJIC",
        "outputId": "b6592c6e-a8ed-4c0c-c31c-faccdcaf42f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Text:\n",
            " \n",
            "\f\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import pytesseract\n",
        "\n",
        "# Function to download the image from a URL\n",
        "def get_image_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "    return img\n",
        "\n",
        "# Example image URL\n",
        "image_url = 'https://m.media-amazon.com/images/I/318TVw4iM1L.jpg'\n",
        "\n",
        "# Download and open the image\n",
        "image = get_image_from_url(image_url)\n",
        "\n",
        "# Use Tesseract to extract text from the image\n",
        "text = pytesseract.image_to_string(image)\n",
        "\n",
        "# Print the extracted text\n",
        "print(\"Extracted Text:\")\n",
        "print(text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Heavyweight**\n"
      ],
      "metadata": {
        "id": "EbyMRquBz7ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "from io import BytesIO\n",
        "import easyocr\n",
        "\n",
        "# Enable GPU for faster performance in Colab\n",
        "reader = easyocr.Reader(['en'], gpu=True)\n",
        "\n",
        "# Function to download the image from a URL\n",
        "def get_image_from_url(url):\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        img = Image.open(BytesIO(response.content))\n",
        "        return img\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching image: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to preprocess the image for faster OCR\n",
        "def preprocess_image(image):\n",
        "    image = image.convert(\"L\")  # Convert to grayscale\n",
        "    image = image.filter(ImageFilter.MedianFilter())  # Light median filter for noise reduction\n",
        "    return image\n",
        "\n",
        "# Resize image to a max width (optional)\n",
        "def resize_image(image, max_width=1000):\n",
        "    width_percent = max_width / float(image.size[0])\n",
        "    height_size = int(float(image.size[1]) * width_percent)\n",
        "    return image.resize((max_width, height_size), Image.ANTIALIAS)\n",
        "\n",
        "# Example image URL\n",
        "image_url = 'https://m.media-amazon.com/images/I/81IYdOV0mVL.jpg'\n",
        "\n",
        "# Download and open the image\n",
        "image = get_image_from_url(image_url)\n",
        "\n",
        "if image:\n",
        "    # Preprocess and resize the image\n",
        "    image = preprocess_image(image)\n",
        "    image = resize_image(image)\n",
        "\n",
        "    # Save the processed image\n",
        "    image.save('image.jpg')\n",
        "\n",
        "    # Run EasyOCR on the processed image with GPU enabled\n",
        "    result = reader.readtext('image.jpg', detail=0)  # Set detail=0 for faster extraction\n",
        "\n",
        "    # Print the extracted text\n",
        "    print(\"Extracted Text:\")\n",
        "    print(' '.join(result))\n",
        "else:\n",
        "    print(\"Failed to download or process the image.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXKfB2Wsx68a",
        "outputId": "d5b06209-4c80-4f62-fde3-e6de32bad862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
            "<ipython-input-11-c49b4d824c60>:30: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  return image.resize((max_width, height_size), Image.ANTIALIAS)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Transformer**"
      ],
      "metadata": {
        "id": "iO7lGfAj1lfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Initialize the Sentence Transformer model\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "# Step 2: Define entities and their associated keywords/units\n",
        "entities = [\"weight\", \"dimensions\", \"volume\", \"voltage\"]\n",
        "units = [\"kg\", \"gram\", \"cm\", \"inch\", \"litre\", \"ml\", \"volt\"]\n",
        "\n",
        "# Step 3: Encode entities into vectors using the sentence transformer\n",
        "entity_embeddings = model.encode(entities)\n",
        "\n",
        "# Step 4: Set up a FAISS index for vector similarity search\n",
        "dimension = entity_embeddings.shape[1]  # Embedding size (typically 768 for this model)\n",
        "index = faiss.IndexFlatL2(dimension)  # L2 distance index\n",
        "index.add(entity_embeddings)  # Add entity embeddings to the FAISS index\n",
        "\n",
        "# Function to find the closest entity using vector search\n",
        "def find_closest_entity(entity_name):\n",
        "    entity_embedding = model.encode([entity_name])\n",
        "    distances, indices = index.search(entity_embedding, 1)  # Top 1 closest result\n",
        "    return entities[indices[0][0]]  # Return the closest entity\n",
        "\n",
        "# Function to extract number + unit pattern from the text\n",
        "def extract_value(text, unit_list):\n",
        "    # Build a regex pattern that looks for a number followed by a unit\n",
        "    pattern = r\"(\\d+(\\.\\d+)?)\\s?(\" + \"|\".join(unit_list) + \")\"\n",
        "    match = re.search(pattern, text)\n",
        "    if match:\n",
        "        return match.group(0)  # Return the full match (e.g., \"500 kg\")\n",
        "    return None\n",
        "\n",
        "# Main function to process the text and find the entity-value pair\n",
        "def get_entity_value(entity_name, text):\n",
        "    # Find the closest entity using vector search\n",
        "    closest_entity = find_closest_entity(entity_name)\n",
        "\n",
        "    # Extract the value associated with the entity\n",
        "    value = extract_value(text, units)\n",
        "\n",
        "    # Return the result as a dictionary or string\n",
        "    if value:\n",
        "        return f\"{closest_entity} = {value}\"\n",
        "    else:\n",
        "        return f\"No value found for {closest_entity}\"\n",
        "\n",
        "# Example usage\n",
        "entity = \"weight\"\n",
        "text = \"the item weighs 500 kg\"\n",
        "result = get_entity_value(entity, text)\n",
        "\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "0OumtLHO1kNT",
        "outputId": "26f4c6da-95a3-46c4-d27c-bbbcfe03978a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sentence_transformers'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-5929e704311d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Testing1**"
      ],
      "metadata": {
        "id": "e1K88FHx2CRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "from io import BytesIO\n",
        "import pytesseract\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Initialize the Sentence Transformer model\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "# Step 2: Define entities and their associated keywords/units\n",
        "entities = [\"weight\", \"dimensions\", \"volume\", \"voltage\"]\n",
        "units = [\"kg\", \"gram\", \"cm\", \"inch\", \"litre\", \"ml\", \"volt\", \"v\"]\n",
        "\n",
        "# Step 3: Encode entities into vectors using the sentence transformer\n",
        "entity_embeddings = model.encode(entities)\n",
        "\n",
        "# Step 4: Set up a FAISS index for vector similarity search\n",
        "dimension = entity_embeddings.shape[1]  # Embedding size\n",
        "index = faiss.IndexFlatL2(dimension)  # L2 distance index\n",
        "index.add(entity_embeddings)  # Add entity embeddings to the FAISS index\n",
        "\n",
        "# Function to find the closest entity using vector search\n",
        "def find_closest_entity(entity_name):\n",
        "    entity_embedding = model.encode([entity_name])\n",
        "    distances, indices = index.search(entity_embedding, 1)  # Top 1 closest result\n",
        "    return entities[indices[0][0]]  # Return the closest entity\n",
        "\n",
        "# Function to extract number + unit pattern from the text\n",
        "def extract_value(text, unit_list):\n",
        "    # Refined regex pattern to handle multiple cases\n",
        "    pattern = r\"(\\d+(\\.\\d+)?)\\s?([\" + \"|\".join(unit_list) + r\"])\"\n",
        "    match = re.search(pattern, text, re.IGNORECASE)  # Added case insensitivity\n",
        "    if match:\n",
        "        return match.group(0)  # Return the full match (e.g., \"500 kg\", \"3.7v\")\n",
        "    return None\n",
        "\n",
        "# Main function to process the text and find the entity-value pair\n",
        "def get_entity_value(entity_name, text):\n",
        "    # Find the closest entity using vector search\n",
        "    closest_entity = find_closest_entity(entity_name)\n",
        "\n",
        "    # Extract the value associated with the entity\n",
        "    value = extract_value(text, units)\n",
        "\n",
        "    # Return the result as a dictionary or string\n",
        "    if value:\n",
        "        return f\"{closest_entity} = {value}\"\n",
        "    else:\n",
        "        return f\"No value found for {closest_entity}\"\n",
        "\n",
        "# Step 5: Function to download and preprocess the image\n",
        "def get_image_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "\n",
        "    # Preprocess the image for better OCR\n",
        "    img = preprocess_image(img)\n",
        "    return img\n",
        "\n",
        "# Preprocessing function to improve OCR accuracy\n",
        "def preprocess_image(image):\n",
        "    # Convert to grayscale\n",
        "    image = image.convert(\"L\")\n",
        "\n",
        "    # Apply thresholding to increase contrast\n",
        "    image = image.point(lambda p: p > 128 and 255)  # Simple thresholding\n",
        "\n",
        "    # Optionally, apply a slight blur to remove noise\n",
        "    image = image.filter(ImageFilter.MedianFilter(size=3))\n",
        "\n",
        "    return image\n",
        "\n",
        "# Step 6: Main function to extract text from image and process entity-value extraction\n",
        "def process_image(image_url, entity_name):\n",
        "    # Download and open the image\n",
        "    image = get_image_from_url(image_url)\n",
        "\n",
        "    # Use Tesseract to extract text from the image\n",
        "    text = pytesseract.image_to_string(image)\n",
        "\n",
        "    # Print the extracted text for debugging\n",
        "    print(\"Extracted Text:\")\n",
        "    print(text)\n",
        "\n",
        "    # Process the text to find entity-value pair\n",
        "    result = get_entity_value(entity_name, text)\n",
        "\n",
        "    # Print the final result\n",
        "    print(f\"Result for '{entity_name}': {result}\")\n",
        "\n",
        "# Example usage:\n",
        "image_url = 'https://m.media-amazon.com/images/I/21vv80MKQEL.jpg'\n",
        "entity = \"volt\"\n",
        "process_image(image_url, entity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByE53u662B3D",
        "outputId": "c0349cb7-4c9d-4ab5-b827-5d19df5c8f32"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Text:\n",
            " \n",
            "\f\n",
            "Result for 'volt': No value found for voltage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Testing2**"
      ],
      "metadata": {
        "id": "HWvOGHed-sbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "from io import BytesIO\n",
        "import pytesseract\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Initialize the Sentence Transformer model\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "# Step 2: Define entities and their associated keywords/units\n",
        "entities = [\"weight\", \"dimensions\", \"volume\", \"voltage\"]\n",
        "units = [\"kg\", \"gram\", \"cm\", \"inch\", \"litre\", \"ml\", \"volt\", \"v\", \"oz\"]\n",
        "\n",
        "# Step 3: Encode entities into vectors using the sentence transformer\n",
        "entity_embeddings = model.encode(entities)\n",
        "\n",
        "# Step 4: Set up a FAISS index for vector similarity search\n",
        "dimension = entity_embeddings.shape[1]  # Embedding size\n",
        "index = faiss.IndexFlatL2(dimension)  # L2 distance index\n",
        "index.add(entity_embeddings)  # Add entity embeddings to the FAISS index\n",
        "\n",
        "# Function to find the closest entity using vector search\n",
        "def find_closest_entity(entity_name):\n",
        "    entity_embedding = model.encode([entity_name])\n",
        "    distances, indices = index.search(entity_embedding, 1)  # Top 1 closest result\n",
        "    return entities[indices[0][0]]  # Return the closest entity\n",
        "\n",
        "# Function to extract number + unit pattern from the text\n",
        "def extract_value(text, unit_list):\n",
        "    # Refined regex pattern to handle multiple cases\n",
        "    pattern = r\"(\\d+(\\.\\d+)?)\\s?([\" + \"|\".join(unit_list) + r\"])\"\n",
        "    match = re.search(pattern, text, re.IGNORECASE)  # Added case insensitivity\n",
        "    if match:\n",
        "        return match.group(0)  # Return the full match (e.g., \"500 kg\", \"3.7v\")\n",
        "    return None\n",
        "\n",
        "# Main function to process the text and find the entity-value pair\n",
        "def get_entity_value(entity_name, text):\n",
        "    # Find the closest entity using vector search\n",
        "    closest_entity = find_closest_entity(entity_name)\n",
        "\n",
        "    # Extract the value associated with the entity\n",
        "    value = extract_value(text, units)\n",
        "\n",
        "    # Return the result as a dictionary or string\n",
        "    if value:\n",
        "        return f\"{closest_entity} = {value}\"\n",
        "    else:\n",
        "        return f\"No value found for {closest_entity}\"\n",
        "\n",
        "# Preprocessing function to improve OCR accuracy\n",
        "def preprocess_image(image):\n",
        "    # Convert to grayscale\n",
        "    image = image.convert(\"L\")\n",
        "\n",
        "    # Apply thresholding to increase contrast\n",
        "    image = image.point(lambda p: p > 128 and 255)  # Simple thresholding\n",
        "\n",
        "    # Optionally, apply a slight blur to remove noise\n",
        "    image = image.filter(ImageFilter.MedianFilter(size=3))\n",
        "\n",
        "    return image\n",
        "\n",
        "# Step 5: Function to download the image from a URL\n",
        "def get_image_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "\n",
        "    # Preprocess the image for better OCR\n",
        "    img = preprocess_image(img)\n",
        "    return img\n",
        "\n",
        "# Step 6: Main function to extract text from image and process entity-value extraction\n",
        "def process_image(image_url, entity_name):\n",
        "    # Download and open the image\n",
        "    image = get_image_from_url(image_url)\n",
        "\n",
        "    # Use Tesseract to extract text from the image\n",
        "    text = pytesseract.image_to_string(image)\n",
        "\n",
        "    # Print the extracted text for debugging\n",
        "    print(\"Extracted Text:\")\n",
        "    print(text)\n",
        "\n",
        "    # Process the text to find entity-value pair\n",
        "    result = get_entity_value(entity_name, text)\n",
        "\n",
        "    # Print the final result\n",
        "    print(f\"Result for '{entity_name}': {result}\")\n",
        "\n",
        "# Example usage:\n",
        "image_url = 'https://m.media-amazon.com/images/I/3131mkESkQL.jpg'\n",
        "entity = \"oz\"\n",
        "process_image(image_url, entity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcNXhpAK-rs6",
        "outputId": "1a62f21f-c71b-41bf-9e78-b5ecd7658cce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Text:\n",
            " \n",
            "\f\n",
            "Result for 'oz': No value found for weight\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "EbyMRquBz7ym",
        "iO7lGfAj1lfz"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}